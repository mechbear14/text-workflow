Using A.I. to Create Music with Ampermusic and Jukedeck | Anarchyjim

For the last 14 years Ive created the Audio Art Tour for Burning Man. Its kind of a docent led audio guide to the major art installations out there, similar to anaudio guide you might get at a museum.
Burning Man always has a different theme and this year it was I, Robot. I generally try and find background music related to the theme. EDM is big at Burning Man, land of 10,000 DJs, so I couldve just grabbed some electronic tracks that sounded robotic. Easy enough to do. However I decided to let Artificial Intelligence algorithms create the music! (You can listen to the tour and hear the different tracks)
This turned out to be not so easy, so Ill break down what I had to do to get seven unique sounding, usable tracks. I had a bit more success with AmperMusic, which is also currently free (unlike Jukedeck), so Ill discuss that first.
Getting the Tracks
The problem with both services was getting unique sound tracks. The A.I. has a tendency of creating very similar sounding music. Even if you select different styles and instruments you often end up with oddly similar music. This problem is compounded by Ampers inability to render more than about 30 seconds of music.

What I found I had to do was let it generate 30 seconds randomly or with me selecting the instruments. I did this repeatedly until I got a 30 second sample I liked. At which point I extended it out to about 3 or 4 minutes and turned off all the instruments but two or three. Amper was usually able to render that out. Then Id turn off those instruments and turn back on another three. Then render that. Rinse, repeat until youve rendered all the instruments.
Now youve got a bunch of individual tracks that you can combine to get your final music track. Combine them in Audition or even Premiere Pro (or FCP or whatever NLE) and youre good to go. I used that technique to get five of the tracks.
Jukedeck didnt have the rendering problem but it REALLY suffered from the sameness problem. It was tough getting something that really sounded unique. However, I did get a couple good tracks out of it.
Problems Using Artificial Intelligence
This is another example of A.I. and Machine Learning that works sort of. I could have found seven stock music tracks that I like much faster (this is what I usually do for the Audio Art Tour). The amount of time it took me messing around with these services was significant. Also, if Jukedeck is any indication, a music track from one of these services will cost as much as a stock music track. Just go to Pond5 to see what you can get for the same price. With a much, much wider variety. I dont think living, breathing musicians have much to worry about. At least for now.
That said, I did manage to get seven unique, cool sounding tracks out of them. It took some work, but it did happen.
As with most A.I./ML, its difficult to see what the future looks like. There has certainly been a ton of advances, but I think in a lot of cases, its some ofthe low hanging fruit. Were seeing that with Speech-to-text algorithms in Transcriptive where theyre starting to plateau and cluster around the same accuracy levels. The fruit (accuracy) is now pretty high up and improvement are tough. Itll be interesting to see what it takes to break through that. More data? Faster servers? A new approach?
I think music may be similar. It seems like its a natural thing for A.I. but its deceptively difficult to do in a way that mimics the range and diversity of styles and sounds that many human musicians have. Particularly a human armed with a synth that can reproduce an entire orchestra. Well see what it takes to get A.I. music out of the Valley of Sameness.
 
